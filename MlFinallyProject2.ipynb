{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c0e7d4",
   "metadata": {},
   "source": [
    "PassengerId ->Her yolcu için farklı yolcu numarasıolduğundan işimize yaramayacaktır\n",
    "Survived -> Hayatta kalıp kalmadığı bilgisi, 0=Hayır | 1=Evet\n",
    "Pclass -> Bilet sınıfı, 1=Üst Sınıf | 2= Orta Sınıf / 3=Alt Sınıf\n",
    "Name -> Yolcuların ismi\n",
    "Sex -> Yolcuların cinsiyeti, male:Erkek, female:Kadın\n",
    "Age -> Yolcuların yaşı\n",
    "SibSp -> Eşe sahip olup olmadığı, 0=Hayır | 1=Evet\n",
    "Parch -> Çocuğu olup olmadığı, 0-1-2-3-4-5-6\n",
    "Ticket -> Bilet numarası\n",
    "Cabin -> Kabin numarası\n",
    "Embarked -> Gemiye biniş limanı, C=Cherbourg / S=Southampton / Q=Queenstown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a00836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71a6bc",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "df=data.copy()\n",
    "#In data science, it is common practice to split the dataset into training and testing sets to evaluate the performance of machine learning models.\n",
    "#The copy of the dataset will be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5ca53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2151c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head().T #getting the first five rows of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8e49e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.tail().T #Displaying the last five rows of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c44a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info() #information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T  #verilerin genel bilgilerinin değerleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns in a dataset (Optional)\n",
    "\"\"\"\n",
    "df=df.rename(columns={\"PassengerId\":\"yolcu_id\",\"Survived\":\"hayatta_kalma\",\"Pclass\":\"Ekonomi_sınıfı\",\n",
    "                      \"Name\":\"isim\",\"Sex\":\"cinsiyet\",\"Age\":\"yaş\",\"SibSp\":\"kardeş_sayısı\",\n",
    "                      \"Parch\":\"çocuk_sayısı\",\"Ticket\":\"bilet\",\"Fare\":\" bilet_fiyatı\",\"Cabin\":\"kabin\",\n",
    "                      \"Embarked\":\"biniş_limanı\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784792d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().values #Missing values may not be fully ımputed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b210d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().values.any() # Are there any missing values?\" and \"TRUE\" indicates that there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() #It shows the total number of missing values in the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784c90b",
   "metadata": {},
   "source": [
    "# Filling in missing numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29588ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the missing numerical data types with the mean value\n",
    "df.fillna(df.mean(),inplace=True)\n",
    "#df['Age'].fillna(df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d18985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.Survived.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741c67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The number of unique values in the separated groups\n",
    "for i in df.columns:\n",
    "    print((\"\\n{}\\n{}\\n\").format(i,df[i].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1 # Calculate the number of family members\n",
    "df.groupby('FamilySize')['Survived'].mean() # Calculate the survival rates by family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dafa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip()) #Detect the titles of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6becd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title')['Survived'].sum().sort_values(ascending=False)\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f26758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the survival rate of each passenger based on their title\n",
    "df.groupby('Title')['Survived'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1c9e6",
   "metadata": {},
   "source": [
    "I am deleting the columns that I think will not be useful for my work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Deleting a large number of columns may seem like a mistake at first glance,\n",
    "but we can look at the unique values in the columns of our dataset to determine whether this process is appropriate.\n",
    "For instance, some columns such as passenger IDs are unique and cannot be related to any other data. \n",
    "Therefore, deleting columns such as passenger ID, cabin, and ticket number may be a reasonable approach. \n",
    "The information contained in these columns may not be useful for analysis or cannot be related to data in other columns.\n",
    "would be the English translation of the given text.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41420207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"FamilySize\", \"Title\", \"Cabin\", \"Name\", \"Ticket\", \"PassengerId\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca594f",
   "metadata": {},
   "source": [
    "# Filling in missing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c999f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #We converted the values of male and female for gender into 0 and 1, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Embarked\"] = df[\"Embarked\"].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc705b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_eco =preprocessing.LabelEncoder()\n",
    "df[\"Embarked\"]=label_eco.fit_transform(df[\"Embarked\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a6193",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05408356",
   "metadata": {},
   "outputs": [],
   "source": [
    "?sns.clustermap #bu şekilde clustermap için kullanılan parametreleri inceleyebilirim gelen bilgi kutucuğundan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(),annot=True,vmin=-1,vmax=1,figsize=(10,10),dendrogram_ratio=0.4,cmap='YlGnBu')\n",
    "\"\"\"\n",
    "min ve max değerlerini -1 e 1 olarak belirlediğim için burada aynı zamanda korelasyon ilişkisini de inceleyebiliyorum\n",
    "(fare ile pclass)=-0.55  aralarında negatif güçlü korelasyon var ekonomi sınıfı arttıkça fiyat değeri artıyor.\n",
    "\n",
    "(survived ile sex)=-0.54 aralarında negatif güçlü korelasyon var male(1) female(0) olarak kategorik verileri \n",
    "değiştirmiştik yani kadınların hayatta kalması daha olası erkeklerden fazla hayatta kalmışlar.\n",
    "\n",
    "(survived ile pclass)=hayatta kalanların sınıfınında burada önemli olduğunu görüyoruz.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "notnumeric=['PassengerId', 'Survived', 'Pclass',  'Age', 'SibSp', 'Parch',  'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Survived\"].value_counts().plot.pie(legend=True,autopct=\"%5.1f%%\") #hayatta kalanların az olduğunu görüyoruz %38 ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5326374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sex\"].value_counts().plot.pie(legend=True,autopct=\"%0.2f%%\") #woman(0),man(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pclass\"].value_counts().plot.pie(legend=True,autopct=\"%0.2f%%\")\n",
    "#Ticket class, 1 Upper Class / 2 Middle Class / 3 Lower Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d981d13",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.countplot(df[\"Survived\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SurvAge = sns.FacetGrid(df, col=\"Survived\")\n",
    "SurvAge.map(plt.hist, 'Age', bins=10) #  30 yaş aralığında 200 den fazla kişi hayatını kaybetmiş."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Pclass', y = 'Survived', data =df) \n",
    "#It has been observed that people who purchase tickets from the lower class have a lower survival rate, whereas those who purchase tickets from the first class have a higher survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Embarked\"].value_counts().plot.pie(legend=True,autopct=\"%0.2f%%\")\n",
    "#Gemiye biniş limanı  0=C=Cherbourg \\ 2=S=Southampton \\ 1=Q=Queenstown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.Age,kde=True,bins=30) #yaş aralığı burada aykırı değerler olduğunu görüyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"Pclass\",x=\"Fare\",data=df,hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e028ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"Age\",x=\"Fare\",data=df,hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm yolcuların yaşa göre gruplandırması\n",
    "age_groups = pd.cut(df[\"Age\"], bins=[0, 18, 30, 50, 100])\n",
    "\n",
    "# Her yaş grubundaki ölen yolcu sayısı hesaplanır\n",
    "group_counts = age_groups.value_counts().sort_values(ascending=False)\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sadece ölen yolcuların  yaşa göre gruplandırması\n",
    "dead_passengers = df[df[\"Survived\"] == 0]\n",
    "\n",
    "# Yaşa göre gruplandırma yapılır\n",
    "age_groups = pd.cut(dead_passengers[\"Age\"], bins=[0, 18, 30, 50, 100])\n",
    "\n",
    "# Her yaş grubundaki ölen yolcu sayısı hesaplanır\n",
    "group_counts = age_groups.value_counts().sort_values(ascending=False)\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff374f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sadece ölen yolcular seçilir\n",
    "dead_passengers = df[df[\"Survived\"] == 1]\n",
    "\n",
    "# Yaşa göre gruplandırma yapılır\n",
    "age_groups = pd.cut(dead_passengers[\"Age\"], bins=[0, 18, 30, 50, 100])\n",
    "\n",
    "# Her yaş grubundaki ölen yolcu sayısı hesaplanır\n",
    "group_counts = age_groups.value_counts().sort_values(ascending=False)\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e502d7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Yolcuların yaş ve sınıflarına göre hayatta kalma durumları\n",
    "\n",
    "spca = sns.FacetGrid(df, col='Survived', row='Pclass', size=3, aspect=2)\n",
    "spca.map(plt.hist, 'Age', alpha=1, bins=25)\n",
    "#alt sınıfta 3 olan pclass ta 30 ta hayatta kalma olasığı çok az \n",
    "#birici sınıfta 1 olan pclass ta 3.sınıfa göre hayatta kalma olasığı fazla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f310a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(dataframe,i):\n",
    "    \n",
    "    sns.boxplot(x=dataframe[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2ef12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_plot(df,\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df,\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcde3d2",
   "metadata": {},
   "source": [
    "aykırı değerlerden kurtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Threshold'ların belirlenmesi:\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n",
    "    q1 = dataframe[col_name].quantile(q1)  # 1.Çeyrek\n",
    "    q3 = dataframe[col_name].quantile(q3)  # 3.Çeyrek\n",
    "    interquantile_range = q3 - q1  # range'i hesaplayalım\n",
    "    low_limit = q1 - 0.8 * interquantile_range # low & up limit:\n",
    "    up_limit = q3 + 0.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "# Outlier Değer Var mı Yok Mu:\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Outlier Değerlere Erişmek:\n",
    "def grab_outliers(dataframe, col_name, index=False):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)].shape[0] > 10:\n",
    "        print(dataframe[(dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)].head())\n",
    "    else:\n",
    "        print(dataframe[(dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)])\n",
    "    if index:\n",
    "        outlier_index = dataframe[(dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)].index\n",
    "        return outlier_index\n",
    "\n",
    "# Outlier Değer Problemini Çözme:\n",
    "\n",
    "# Silme ile remove_outlier çözümleme:\n",
    "def remove_outlier (dataframe, col_name, q1=0.05, q3=0.95):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n",
    "    return df_without_outliers\n",
    "\n",
    "# Baskılama yöntemi:\n",
    "def replace_with_thresholds(dataframe, variable, q1=0.01, q3=0.99):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1, q3)\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006a623",
   "metadata": {},
   "source": [
    "yaş için outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_thresholds(df,\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55eac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outlier(df,\"Age\") \n",
    "#aykırı olan 80 yaş için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bf02b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grab_outliers(df,\"Age\") #aykırı olan değer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b724a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outlier(df,\"Age\")#sadece bir satırı sildim diğer değerlerin aykırı olduğunu düşünmüyorum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9733702",
   "metadata": {},
   "source": [
    "fare için outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20885d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_thresholds(df,\"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outlier(df,\"Fare\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d177a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_outliers(df,\"Fare\") #aykırı olan değer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_thresholds(df,\"Fare\")# burada aykırı değerleri silmek yerine baskılama yöntemi kullandım"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bba071",
   "metadata": {},
   "source": [
    "SibSp için outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_thresholds(df,\"SibSp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outlier(df,\"SibSp\") #aykırı değerim var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_outliers(df,\"SibSp\") #aykırı olan değer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_thresholds(df,\"SibSp\")# burada aykırı değerleri silmek yerine baskılama yöntemi kullandım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d48d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df,\"Fare\") \n",
    "#fare için aykırı değerlerimizi baskıladık 0-500 arasında olan sıkalayı 0-350 arasına çektik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df,hue='Survived',height=2,palette=\"Dark2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "spca = sns.FacetGrid(df, col='Survived', row='Pclass', size=3, aspect=2)\n",
    "spca.map(plt.hist, 'Age', alpha=1, bins=25)\n",
    "spca.add_legend()\n",
    "# 3.sınıf pclass ta 30 yaş aralığında hayatta kalma olasılığı çok az\n",
    "#pclass 3 ile pclass 1arasında hayatta kalma oranına bakacak olursak 3. sınıfta hayatta kalmak daha azihtimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa56ed9",
   "metadata": {},
   "source": [
    "5 farklı yeni dummy (kukla) değişkeni elde etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30abf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked değerlerinin kukla dönüşümü için one hot Encoding kullanıyorum\n",
    "#kategorik değişkenlerin ikili (binary) olarak dönüştürülmesi anlamına gelmekte ,\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dummy = pd.get_dummies(df[\"Embarked\"])   \n",
    "dummy_ = df.drop(columns=\"Embarked\", axis=1)            \n",
    "df = pd.concat([dummy_, dummy],axis=1)      \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sex değerlerlerinin kukla dönüşümü için one hot Encoding kullanıyorum\n",
    "dummy2 = pd.get_dummies(df[\"Sex\"])   \n",
    "dummy_2 = df.drop(columns=\"Sex\", axis=1)            \n",
    "df = pd.concat([dummy_2,dummy2],axis=1)               \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec60d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sütunların isimlerini değiştirme yapabiliriz\n",
    "df=df.rename(columns={0:\"Male\",1:\"Female\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"C\",\"Q\",\"S\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784128a",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df011dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Pclass',\"female\",\"male\",'Age','Fare',\"SibSp\"]]\n",
    "x.head(2) #Bağımsız değişkenler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e91b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"Survived\"]\n",
    "df.head() #Bağımlı değişken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e12f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train ve test olarak ayırdım \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.12, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_regresyon=LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000)\n",
    "\n",
    "log_regresyon.fit(x_train,y_train)\n",
    "log_regresyon.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verilerin olceklenmesi- standardizasyon\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss=StandardScaler()\n",
    "\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33742c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def metrik_yazdirma(df):\n",
    "    print(\"Yüzde Başarı Değeri: {}%\".format(accuracy_score(y_test, y_pred)*100))\n",
    "    print(\"Accuracy Değeri: {}\".format( accuracy_score(y_test, y_pred)))\n",
    "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "    print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler objesi oluşturma\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler\n",
    "#veriyi normalize hale getirmek için -1,1 aralığına sığdırır\n",
    "df_std = pd.DataFrame(std_scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# The best success was achieved when k=3.\n",
    "score=[]\n",
    "for k in range(1,10,2):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    score.append(metrics.accuracy_score(y_test,y_pred))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab805e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB and BernoulliNB \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gauss_ = GaussianNB()\n",
    "gauss_.fit(x_train, y_train)\n",
    "\n",
    "y_pred = gauss_.predict(x_test)\n",
    "\n",
    "metrik_yazdirma(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rd_forest = RandomForestClassifier(n_estimators=100)\n",
    "rd_forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rd_forest.predict(x_test)\n",
    "\n",
    "metrik_yazdirma(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee0211",
   "metadata": {},
   "source": [
    "Accuracy, sınıflandırıcının doğru tahmin etme oranını ölçen bir metrik olarak tanımlanır ve aşağıdaki formülle hesaplanır:\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Burada, TP (True Positive) doğru pozitif sınıflandırmaların sayısını, TN (True Negative) doğru negatif sınıflandırmaların sayısını, FP (False Positive) yanlış pozitif sınıflandırmaların sayısını ve FN (False Negative) yanlış negatif sınıflandırmaların sayısını temsil eder.\n",
    "\n",
    "Precision, tüm pozitif tahminlerin kaçının doğru olduğunu ölçen bir metriktir ve aşağıdaki formülle hesaplanır:\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Recall, pozitif sınıfların kaçının doğru şekilde tahmin edildiğini ölçen bir metriktir ve aşağıdaki formülle hesaplanır:\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "F1 Score, Precision ve Recall metriklerinin harmonik ortalaması olarak tanımlanır ve aşağıdaki formülle hesaplanır:\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Burada, Precision ve Recall metriklerinin değerleri, doğru pozitif (TP), yanlış pozitif (FP) ve yanlış negatif (FN) tahminlerin sayılarına göre hesaplanır.\n",
    "\n",
    "Random Forest, KNN ve Naive Bayes algoritmaları arasından en iyi başarı oranını elde eden algoritma Random Forest olarak belirtilmiştir. Başarı oranı %85.04 olarak hesaplanmıştır."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
